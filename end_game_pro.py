# -*- coding: utf-8 -*-
"""end_game_pro.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14x7YUVyA8ZZUL7A-84HmjWk4TYnP05Xg
"""



import pandas as pd
df=pd.read_csv('modelsupported_10.csv')
df.drop('Unnamed: 0',axis=1,inplace=True)

df.shape

df.drop(['TOTAL_SCORE'],axis=1,inplace=True)

df.to_csv('modelsupported_10.csv')

df.head()

for i in df.columns:
  print(i,sep='')

for i in testdata.columns:
  print(i,sep='')

"""### FULL TIME RESULT MODEL"""

from google.colab import drive
drive.mount('/content/drive')

import os
api_key = os.getenv("2285093cfdcc0d1e0fe20e990a4179bb")

import pandas as pd
from sklearn.model_selection import train_test_split
import xgboost as xgb
from sklearn.metrics import accuracy_score
from sklearn.metrics import  confusion_matrix


df1=df2=df


X,y=df1.iloc[:,:-1], df1.iloc[:,-1]
X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.10,stratify=y, random_state=500)
xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=400, seed=123,max_depth=5,
                          learning_rate=0.3,n_jobs=-1,random_state=125,colsample_bytree=0.9,
                          gamma=0.02,reg_lambda=0.01,min_samples_leaf=8,max_features='auto',loss='exponential'
                          ,min_samples_split=8
                          )
xg_cl.fit(X_train,y_train)
predict = xg_cl.predict(X_test)
acc = accuracy_score(predict, y_test)
print("Test set accuracy: {:.2f}".format(acc))

"""### FEATURE IMPORTANCE"""

X_train.shape

testdata.shape



import matplotlib.pyplot as plt

importances = pd.Series(data=xg_cl.feature_importances_,
                        index= X_train.columns)

# Sort importances
importances_sorted = importances.sort_values()

# Draw a horizontal barplot of importances_sorted
from matplotlib.pyplot import figure
figure(num=None, figsize=(40, 40), dpi=80, facecolor='w', edgecolor='k')
importances_sorted.plot(kind='barh', color='red')
plt.title('Features Importances')
plt.show()

"""### **CHECK WHETHER TEST DATA IS PRESENT**"""

#making sure that test data doesnt come 
X_test[(X_test['HomeTeam_Man United']==1)&(X_test['AwayTeam_Tottenham']==1)]

X_train.head()

df.shape

testdata.head()



X_train.head()



"""### ***TEST FULL TIME RESULT***"""

testdata.head()

testdata=pd.read_csv('liver_wolves.csv')
predict = xg_cl.predict(testdata)

testdata.head()

predict

k=X_test.to_csv('testtemplacte.csv')

for i in testdata.columns:
  print(i,sep='')

"""### **HOME PREDICTION**"""

#matrix formula
y_train=y_train.replace(['D','A','H'],[0,0,1])
y_test =y_test.replace(['D','A','H'],[0,0,1])
from sklearn import preprocessing
encoder = preprocessing.LabelEncoder()
y_train = encoder.fit_transform(y_train)
y_test = encoder.fit_transform(y_test)
matrix_train=xgb.DMatrix(data=X_train,label=y_train)


params={'objective':'binary:logistic', 'n_estimators':400,'seed':123,'max_depth':5,
                          'learning_rate':0.02,'n_jobs':-1,'random_state':125,'subsample':0.9,
                          'gamma':0.02,'reg_lambda':0.01,'min_samples_leaf':8,'max_features':'auto','loss':'exponential'
                          ,'min_samples_split':12
}
matrix_train=xgb.DMatrix(data=X_train,label=y_train)
matrix_test3=xgb.DMatrix(data=testdata)
xg_dmat=xgb.train(params=params,dtrain=matrix_train,num_boost_round=300)
prediction=xg_dmat.predict(matrix_test3)
prediction

import numpy as np

prediction[0]=np.where(prediction[0]>=0.5,1,0)
k=pd.DataFrame(prediction)
print(k)

"""### **HYPER PARAMETER TUNING ON REGRESSION MODEL**"""

#CORNER MODEL

# Create the DMatrix: housing_dmatrix
housing_dmatrix = xgb.DMatrix(data=X,label=y)

# Create the parameter dictionary for each tree: params 
params = {"objective":"reg:linear", "max_depth":3}

# Create list of number of boosting rounds
num_rounds = [5, 10, 15]

# Empty list to store final round rmse per XGBoost model
final_rmse_per_round = []

# Iterate over num_rounds and build one model per num_boost_round parameter
for curr_num_rounds in num_rounds:

    # Perform cross-validation: cv_results
    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, num_boost_round=curr_num_rounds, metrics="rmse", as_pandas=True, seed=123)
    
    # Append final round RMSE
    final_rmse_per_round.append(cv_results["test-rmse-mean"].tail().values[-1])

# Print the resultant DataFrame
num_rounds_rmses = list(zip(num_rounds, final_rmse_per_round))
print(pd.DataFrame(num_rounds_rmses,columns=["num_boosting_rounds","rmse"]))

# Create your housing DMatrix
housing_dmatrix = xgb.DMatrix(data=X,label=y)

# Create the parameter dictionary
params={"objective":"reg:linear","max_depth":3}

# Create list of hyperparameter values: colsample_bytree_vals
colsample_bytree_vals = [0.1,0.5,0.8,1]
best_rmse = []

# Systematically vary the hyperparameter value 
for curr_val in colsample_bytree_vals:

    params['colsample_bytree'] = curr_val
    
    # Perform cross-validation
    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,
                 num_boost_round=10, early_stopping_rounds=5,
                 metrics="rmse", as_pandas=True, seed=123)
    
    # Append the final round rmse to best_rmse
    best_rmse.append(cv_results["test-rmse-mean"].tail().values[-1])

# Print the resultant DataFrame
print(pd.DataFrame(list(zip(colsample_bytree_vals, best_rmse)), columns=["colsample_bytree","best_rmse"]))

X_train.columns

test=pd.read_csv('man utd vs chelsea.csv')

predict = xg_cl.predict(test)
print(predict)


k=pd.DataFrame(predict)
k[0].value_counts()

"""*TESTING CROSS VALIDATION ON XG BOOST *
and converting into d matrix
"""

from sklearn.model_selection import cross_val_score
xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=400, seed=123,max_depth=4,
                          learning_rate=0.02,n_jobs=-1,random_state=123,subsample=0.8,
                          gamma=0.4,reg_lambda=1,min_samples_leaf=8,max_features='log',
                          min_samples_split=10,
                          )
print(cross_val_score(xg_cl,X,y,cv=5,scoring='accuracy'))

###### TWEAKING
for i in range(100,1000,100):
  X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.15,stratify=y, random_state=i)
  xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=400, seed=123,max_depth=4,
                          learning_rate=0.02,n_jobs=-1,random_state=125,subsample=0.8,
                          gamma=0.4,reg_lambda=1,min_samples_leaf=8,max_features='auto',
                          min_samples_split=14
                          )
  xg_cl.fit(X_train,y_train)
  predict = xg_cl.predict(X_test)
  acc = accuracy_score(predict, y_test)
  print("Test set accuracy: {:.2f}".format(acc))
  print("Random state: {:.2f}".format(i))

import xgboost as xgb 
import pandas as pd
df1=pd.read_csv('model_supported6.csv')
df1.drop('Unnamed: 0',axis=1,inplace=True)

X,y=df1.iloc[:,:-1], df1.iloc[:,-1]
X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.15,stratify=y, random_state=800)

#matrix formula
y_train=y_train.replace(['D','A','H'],[0,0,1])
y_test =y_test.replace(['D','A','H'],[0,0,1])
from sklearn import preprocessing
encoder = preprocessing.LabelEncoder()
y_train = encoder.fit_transform(y_train)
y_test = encoder.fit_transform(y_test)
matrix_train=xgb.DMatrix(data=X_train,label=y_train)


params={'objective':'binary:logistic', 'n_estimators':400,'seed':123,'max_depth':5,
                          'learning_rate':0.02,'n_jobs':-1,'random_state':125,'subsample':0.9,
                          'gamma':0.02,'reg_lambda':0.01,'min_samples_leaf':8,'max_features':'auto','loss':'exponential'
                          ,'min_samples_split':12
}
matrix_train=xgb.DMatrix(data=X_train,label=y_train)
matrix_test3=xgb.DMatrix(data=testdata)
xg_dmat=xgb.train(params=params,dtrain=matrix_train,num_boost_round=300)
prediction=xg_dmat.predict(matrix_test3)
prediction

y_train=y_train.replace(['D','A','H'],[0,0,1])
y_test =y_test.replace(['D','A','H'],[0,0,1])

from sklearn import preprocessing
encoder = preprocessing.LabelEncoder()
y_train = encoder.fit_transform(y_train)
y_test = encoder.fit_transform(y_test)

matrix_train=xgb.DMatrix(data=X_train,label=y_train)


params={'objective':'binary:logistic', 'n_estimators':400,'seed':123,'max_depth':5,
                          'learning_rate':0.02,'n_jobs':-1,'random_state':125,'subsample':0.9,
                          'gamma':0.02,'reg_lambda':0.01,'min_samples_leaf':8,'max_features':'auto','loss':'exponential'
                          ,'min_samples_split':12
}

matrix_train=xgb.DMatrix(data=X_train,label=y_train)

matrix_test3=xgb.DMatrix(data=testdata)

matrix_test3=xgb.DMatrix(data=test3)

matrix_test=xgb.DMatrix(data=test)
matrix_test1=xgb.DMatrix(data=test1)
matrix_test2=xgb.DMatrix(data=test2)

test

xg_dmat=xgb.train(params=params,dtrain=matrix_train,num_boost_round=300)

predictions4=xg_dmat.predict(matrix_test3)

predictions4

test

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test,predictions4)

acc = accuracy_score(predictions4[0], y_test)
print("Test set accuracy: {:.2f}".format(acc))

predictions4=pd.DataFrame(predictions4)

predictions1=xg_dmat.predict(matrix_test)
predictions2=xg_dmat.predict(matrix_test1)
prediction3=xg_dmat.predict(matrix_test2)

array(['D', 'D', 'D', 'H', 'D', 'H', 'H', 'H', 'H', 'H', 'H'],
      dtype=object)

import numpy as np
predictions4[0]=np.where(predictions4[0]>=0.5,1,0)

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test,pred)

acc = accuracy_score(pred[0], y_test)
print("Test set accuracy: {:.2f}".format(acc))

"""BAGGING CLASSIFIER (LOW BIAS + HIGH VARIANCE ) --- > AT FINAL 
IT COMES TO LOW BIAS AND REDUCED VARIANCE
"""

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import  accuracy_score
# Instantiate the base model
clf_dt = DecisionTreeClassifier(max_depth=4)

# Build and train the Bagging classifier
clf_bag = BaggingClassifier(
  base_estimator=clf_dt,
  n_estimators=121,
  random_state=500,
  max_features=35)

clf_bag.fit(X_train, y_train)

# Predict the labels of the test set
pred = clf_bag.predict(X_test)

# Show the F1-score
print('accuracy_score: {:.3f}'.format(accuracy_score(y_test, pred)))

# Build a balanced logistic regression
from sklearn.tree import DecisionTreeClassifier

clf_base = DecisionTreeClassifier(max_depth=5, random_state=42)

# Build and fit a bagging classifier with custom parameters
clf_bag = BaggingClassifier(base_estimator=clf_base,n_estimators=500, 
max_features=10, max_samples=0.65, bootstrap=False,random_state=500)
clf_bag.fit(X_train, y_train)

# Calculate predictions and evaluate the accuracy on the test set
y_pred = clf_bag.predict(X_test)
print('Accuracy:  {:.2f}'.format(accuracy_score(y_test, y_pred)))

# Build and train the bagging classifier
clf_bag = BaggingClassifier(
  base_estimator=clf_dt,
   n_estimators=21,
  oob_score=True,
  random_state=500)
clf_bag.fit(X_train, y_train)

# Print the out-of-bag score
print('OOB-Score: {:.3f}'.format(clf_bag.oob_score_))

# Evaluate the performance on the test set to compare
pred = clf_bag.predict(X_test)
print('Accuracy: {:.3f}'.format(accuracy_score(y_test, pred)))
print(confusion_matrix(y_test, pred))

#stacking classifier 

# Instantiate the first-layer classifiers
clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)
clf_knn = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree')

# Instantiate the second-layer meta classifier
clf_meta = DecisionTreeClassifier(random_state=500)

# Build the Stacking classifier
clf_stack = StackingClassifier(classifiers=[clf_dt, clf_knn], meta_classifier=clf_meta, use_features_in_secondary=True)
clf_stack.fit(X_train, y_train)

# Evaluate the performance of the Stacking classifier
pred_stack = clf_stack.predict(X_test)
print("Accuracy: {:0.4f}".format(accuracy_score(y_test, pred_stack)))

# Instantiate the 1st-layer regressors
reg_dt = DecisionTreeRegressor(min_samples_leaf=11, min_samples_split=33, random_state=500)
reg_lr = LinearRegression(normalize=True)
reg_ridge = Ridge(random_state=500)

# Instantiate the 2nd-layer regressor
reg_meta = LinearRegression()

# Build the Stacking regressor
reg_stack = StackingRegressor(regressors=[reg_dt, reg_lr, reg_ridge], meta_regressor=reg_meta,use_features_in_secondary=True)
reg_stack.fit(X_train, y_train)

# Evaluate the performance on the test set using the MAE metric
pred = reg_stack.predict(X_test)
print('MAE: {:.3f}'.format(mean_absolute_error(y_test, pred)))

"""import numpy as np
df['my_channel'] = np.where(df.my_channel > 20000, 0, df.my_channel)


-----------------------
df['X'] = np.where(df['Y']>=50, 'yes', 'no')
-------------------------------------------------------
f = lambda x: 0 if x>100 else 1
df['my_column'] = df['my_column'].map(f)
"""

pred=pd.DataFrame(data=predictions)

import numpy as np
pred[0]=np.where(pred[0]>0.15403634,1,0)

pred[0]

acc = accuracy_score(pred[0], y_test)
print("Test set accuracy: {:.2f}".format(acc))

y_train.value_counts()

len(y_train)
k=322/1033
print(k)

y_test.value_counts()

predict = xg_cl.predict(X_train)
acc = accuracy_score(predict, y_train)
print("Test set accuracy: {:.2f}".format(acc))

test=pd.read_csv('match3.csv')

predict = xg_cl.predict(test)

predict

probability=xg_cl.predict_proba(test)

#hyperparmeter tuning
# Create the parameter grid: gbm_param_grid
gbm_param_grid = {
    'colsample_bytree': [0.3, 0.7],
    'n_estimators': [50],
    'max_depth': [2, 5]
}

# Instantiate the regressor: gbm
gbm = xgb.XGBRegressor()

# Perform grid search: grid_mse
grid_mse = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid,
                        scoring='neg_mean_squared_error', cv=4, verbose=1)
grid_mse.fit(X, y)

# Print the best parameters and lowest RMSE
print("Best parameters found: ", grid_mse.best_params_)
print("Lowest RMSE found: ", np.sqrt(np.abs(grid_mse.best_score_)))

# Create the parameter grid: gbm_param_grid 
gbm_param_grid = {
    'n_estimators': [25],
    'max_depth': range(2, 12)
}

# Instantiate the regressor: gbm
gbm = xgb.XGBRegressor(n_estimators=10)

# Perform random search: grid_mse
randomized_mse = RandomizedSearchCV(estimator=gbm, param_distributions=gbm_param_grid,
                                    n_iter=5, scoring='neg_mean_squared_error', cv=4, verbose=1)
randomized_mse.fit(X, y)

# Print the best parameters and lowest RMSE
print("Best parameters found: ",randomized_mse.best_params_)
print("Lowest RMSE found: ", np.sqrt(np.abs(randomized_mse.best_score_)))

# Build and fit linear regression model
reg_lm = LinearRegression(normalize=True)
reg_lm.fit(X_train, y_train)

# Calculate the predictions on the test set
pred = reg_lm.predict(X_test)
#.predict(X_testEvaluate the performance using the RMSE
rmse = np.sqrt(mean_squared_error(y_test,pred))
print('RMSE: {:.3f}'.format(rmse))

"""Boosting for predicted revenue
The initial model got an RMSE of around 7.34. Let's see if we can improve this using an iteration of boosting.

You'll build another linear regression, but this time the target values are the errors from the base model, calculated as follows:

 **y_train_error = pred_train - y_train
y_test_error = pred_test - y_test**
For this model you'll also use 'popularity' as an additional feature, hoping that it can provide informative patterns than with the 'budget' feature alone. This is available to you as X_train_pop and X_test_pop.
"""

# Fit a linear regression model to the previous errors
reg_error = LinearRegression(normalize=True)
reg_error.fit(X_train_pop,y_train_error)

# Calculate the predicted errors on the test set
pred_error = reg_error.predict(X_test_pop)

# Evaluate the updated performance
rmse_error = np.sqrt(mean_squared_error(y_test_error,pred_error))
print('RMSE: {:.3f}'.format(rmse_error))

# Build and fit a CatBoost regressor
reg_cat = cb.CatBoostRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=500)
reg_cat.fit(X_train, y_train)

# Calculate the predictions on the set set
pred = reg_cat.predict(X_test)

# Evaluate the performance using the RMSE
rmse_cat = np.sqrt(mean_squared_error(y_test, pred))
print('RMSE (CatBoost): {:.3f}'.format(rmse_cat))

"""STACKING"""

# Build and fit a Decision Tree classifier
clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)
clf_dt.fit(X_train,y_train)

# Build and fit a 5-nearest neighbors classifier using the 'Ball-Tree' algorithm
clf_knn = KNeighborsClassifier(n_neighbors=5,algorithm='ball_tree')
clf_knn.fit(X_train,y_train)

# Evaluate the performance using the accuracy score
print('Decision Tree: {:0.4f}'.format(accuracy_score(y_test, clf_dt.predict(X_test))))
print('5-Nearest Neighbors: {:0.4f}'.format(accuracy_score(y_test, clf_knn.predict(X_test))))

"""Building the second-layer classifier
Now you'll work on the next two steps of the process.

Step 3: Append the predictions to the dataset The predictions with the first-layer estimators were already calculated and are available to you as: pred_dt and pred_knn. You'll use these to create a DataFrame and append them to the training features.

Step 4: Build the second-layer meta estimator For this purpose you'll build the default DecisionTreeClassifier. This will take as input feature the concatenation of the original training features and the predictions from the first-layer estimators.
"""

# Create a Pandas DataFrame with the predictions
pred_df = pd.DataFrame({
	'pred_dt': pred_dt,
    'pred_knn': pred_knn
}, index=X_train.index)

# Concatenate X_train with the predictions DataFrame
X_train_2nd = pd.concat([X_train, pred_df], axis=1)

# Build the second-layer meta estimator
clf_stack = DecisionTreeClassifier(random_state=500)
clf_stack.fit(X_train_2nd, y_train)

random_state=[100,201000]xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=400, seed=123,max_depth=4,
                          learning_rate=0.02,n_jobs=-1,random_state=123,subsample=0.8,
                          gamma=0.4,reg_lambda=1,min_samples_leaf=8,max_features='log',
                          min_samples_split=14
                          )